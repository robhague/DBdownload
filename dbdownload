#!/usr/bin/env python

import httplib
import json
import locale
import logging
import os
import subprocess
import sys
import time
import urllib
from base64 import b64decode
from ConfigParser import SafeConfigParser
from optparse import OptionParser
from dropbox import client, session


# globals
# got encoded dropbox app key at
# https://dl-web.dropbox.com/spa/pjlfdak1tmznswp/api_keys.js/public/index.html
APP_KEY = 'bYeHLWKRctA=|ld63MffhrcyQrbyLTeKvTqxE5cQ3ed1YL2q87GOL/g=='
ACCESS_TYPE = 'dropbox'  # should be 'dropbox' or 'app_folder'
LOGGER = 'dbdownload'
VERSION = '0.1'


def decode_dropbox_key(key):
    key, secret = key.split('|')
    key = b64decode(key)
    key = [ord(x) for x in key]
    secret = b64decode(secret)

    s = range(256)
    y = 0
    for x in xrange(256):
        y = (y + s[len(key)] + key[x % len(key)]) % 256
        s[x], s[y] = s[y], s[x]

    x = y = 0
    result = []
    for z in range(len(secret)):
        x = (x + 1) % 256
        y = (y + s[x]) % 256
        s[x], s[y] = s[y], s[x]
        k = s[(s[x] + s[y]) % 256]
        result.append(chr((k ^ ord(secret[z])) % 256))

    # key = ''.join([chr(a) for a in key])
    # return '|'.join([b64encode(key), b64encode(''.join(result))])
    return ''.join(result).split('?', 2)

def remove_trailing_sep(path):
    "A utility to remove trailing path separators from filenames"
    if path[-1] == os.path.sep:
        return path[:-1]
    else:
        return path

class DBDownload(object):
    def __init__(self, remote_dir, local_dir, cache_file, options):
        self._logger = logging.getLogger(LOGGER)

        # Normalize the source and target paths by ensuring that the
        # remote path is absolute, and removing trailing separators
        # from both. This is required for correct functioning of
        # _local2remote() and _remote2local().
        self.remote_dir = remove_trailing_sep(remote_dir.lower())
        if not self.remote_dir.startswith(os.path.sep):
            self.remote_dir = ''.join([os.path.sep, self.remote_dir])
        self.local_dir = remove_trailing_sep(local_dir)

        self.cache_file = cache_file

        self.sleep = options['interval']
        self.num = options['num']
        self.poll = options['poll']

        self.executable = options['exec']

        self._tree = {}
        self._token = None
        self._cursor = None
        self._longpoll_backoff = 0
        self._load_state()

        key, secret = decode_dropbox_key(APP_KEY)
        self.sess = DBSession(key, secret, access_type=ACCESS_TYPE)
        if self._token:
            self.sess.set_token(self._token[0], self._token[1])
        else:
            self._token = self.sess.link()
        self.client = client.DropboxClient(self.sess)

    def reset(self):
        self._logger.debug('resetting local state')
        self._tree = {}
        self._cursor = None
        self._save_state()

    def start(self):
        self._monitor()

    def _local2remote(self, local):
        rootlen = len(self.local_dir.split(os.path.sep))
        x = local.split(os.path.sep)[rootlen:]
        remote = os.path.join(self.remote_dir, *x)
        return remote

    def _remote2local(self, remote):
        rootlen = len(self.remote_dir.split(os.path.sep))
        x = remote.split(os.path.sep)[rootlen:]
        local = os.path.join(self.local_dir, *x)
        return local

    def _monitor(self):
        self._mkdir(self.local_dir)  # make sure root directory exists

        tree = {}
        changed = False
        while True: # May exit with a break if --num is used
            # check for anything missing locally
            changed = self._check_missing()

            # get delta results from Dropbox
            try:
                result = self.client.delta(self._cursor)
            except Exception as e:
                self._logger.error('error getting delta')
                self._logger.exception(e)
                continue
            if result['reset']:
                self._logger.debug('delta reset')

            for path, metadata in result['entries']:
                if os.path.commonprefix([
                    path, self.remote_dir]) == self.remote_dir:
                    tree[path] = metadata

            self._cursor = result['cursor']

            if not result['has_more']:
                if tree:
                    self._apply_delta(tree)
                    merged = dict(self._tree.items() + tree.items())
                    self._tree = dict([(k, v) for k, v in merged.items() if v])
                    changed = True

                rv = self._cleanup_target()  # remove local changes
                if not changed:
                    changed = rv
                self._save_state()

                if changed and self.executable:
                    self._launch(self.executable)

                # Break if we've reached then end of a fixed number of checks
                if self.num > 0:
                    self.num = self.num-1
                    if self.num == 0:
                        break
                    elif self.num == 1:
                        self._logger.debug("1 check remaining")
                    else:
                        self._logger.debug("%d checks remaining" % self.num)

                # done processing delta, wait and check again
                tree = {}

                if self.poll:
                    # Long poll
                    while not self._longpoll_has_changed(): pass
                else:
                    # Fixed sleep
                    self._logger.debug('sleeping for %d seconds' % (self.sleep))
                    time.sleep(self.sleep)

    def _longpoll_has_changed(self):
        time.sleep(self._longpoll_backoff)
        self._longpoll_backoff = 0
        self._logger.debug('Long polling...')
        conn = httplib.HTTPSConnection('api-notify.dropbox.com')
        conn.request('GET', '/1/longpoll_delta?'+
                     urllib.urlencode({'cursor': self._cursor,
                                       'timeout': self.sleep}))
        res = conn.getresponse()
        if res.status == 200:
            data = json.load(res)
            self._longpoll_backoff = int(data.get('backoff',0))
            changes = data.get('changes', True)
            self._logger.debug('Long polling detected changes: %s' % changes)
            return changes
        else:
            # Longpoll failed; sleep the default amount, then assume
            # changes
            self._logger.debug('Long poll failed; sleeping...')
            time.sleep(self.sleep)
            return True


    # launch a program if anything has changed
    def _launch(self, prg):
        try:
            subprocess.Popen([prg], shell=True, stdin=None, stdout=None,
                             stderr=None, close_fds=True)
        except Exception as e:
            self._logger.error('error launching program')
            self._logger.exception(e)

    # load state from our local cache
    def _load_state(self):
        try:
            with open(os.path.expanduser(self.cache_file), 'r') as f:
                dir_changed = False
                try:
                    line = f.readline()  # Dropbox directory
                    directory = json.loads(line)
                    if directory != self.remote_dir:  # don't use state
                        self._logger.info('remote dir changed "%s" -> "%s"' %
                                          (directory, self.remote_dir))
                        dir_changed = True
                except Exception as e:
                    self._logger.warn('can\'t load cache state')
                    self._logger.exception(e)

                try:
                    line = f.readline()  # token
                    self._token = json.loads(line)
                    self._logger.debug('loaded token')
                except Exception as e:
                    self._logger.warn('can\'t load cache state')
                    self._logger.exception(e)
                if dir_changed:
                    return

                try:
                    line = f.readline()  # cursor
                    self._cursor = json.loads(line)
                    self._logger.debug('loaded delta cursor')
                except Exception as e:
                    self._logger.warn('can\'t load cache state')
                    self._logger.exception(e)

                try:
                    line = f.readline()  # tree
                    self._tree = json.loads(line)
                    self._logger.debug('loaded local tree')
                except Exception as e:
                    self._logger.warn('can\'t load cache state')
                    self._logger.exception(e)
        except Exception as e:
            self._logger.error('error opening cache file')
            self._logger.exception(e)

    # update our local state file
    def _save_state(self):
        with open(os.path.expanduser(self.cache_file), 'w') as f:
            f.write(''.join([json.dumps(self.remote_dir), '\n']))
            f.write(''.join([json.dumps(self._token), '\n']))
            f.write(''.join([json.dumps(self._cursor), '\n']))
            f.write(''.join([json.dumps(self._tree), '\n']))

    def _get_modt(self, modstr):
        mod = time.strptime(modstr, '%a, %d %b %Y %H:%M:%S +0000')
        t = time.mktime(mod)
        return t

    # check for files/folders missing or modified locally
    def _check_missing(self):
        dirs = []
        files = []
        changed = False
        for key, meta in self._tree.items():
            if not meta:
                continue
            local_path = self._remote2local(meta['path'])
            t = self._get_modt(meta['modified'])
            if not os.path.exists(local_path):
                if meta['is_dir']:
                    dirs.append((key, local_path))
                else:
                    files.append((key, local_path, t))
            elif not meta['is_dir']:
                stat = os.stat(local_path)
                if stat.st_mtime != t:
                    self._logger.debug('%s has been modified locally' %
                                       (local_path))
                    files.append((key, local_path, t))

        dirs.sort()  # make sure we're creating them in order

        for _, d in dirs:
            self._mkdir(d)
            changed = True

        for k, f, t in files:
            self._get_file(k, f, t)
            changed = True

        return changed

    # apply any outstanding change
    def _apply_delta(self, tree):
        self._logger.debug('applying changes in tree')
        rm = [self._tree[n]['path'] for n in tree if not tree[n] and n in
              self._tree and self._tree[n]]
        rm.sort(reverse=True)
        for path in rm:
            self._remove(self._remote2local(path))  # remove file or directory

        dirs = [n for n in tree if tree[n] and tree[n]['is_dir']]
        dirs.sort()  # make sure we're creating them in order

        for d in dirs:
            rev = d in tree and tree[d]['revision'] or -1
            oldrev = d in self._tree and self._tree[d]['revision'] or -1
            if oldrev < rev:
                local_path = self._remote2local(tree[d]['path'])
                self._mkdir(local_path)

        files = [n for n in tree if tree[n] and not tree[n]['is_dir']]

        for f in files:
            rev = f in tree and tree[f]['revision'] or -1
            oldrev = f in self._tree and self._tree[f]['revision'] or -1
            if oldrev < rev:
                local_path = self._remote2local(tree[f]['path'])
                self._get_file(f, local_path,
                               self._get_modt(tree[f]['modified']))

    # remove anything that is not in dropbox
    def _cleanup_target(self):
        self._logger.debug('cleanup using merged tree')

        changed = False
        for root, dirs, files in os.walk(self.local_dir):
            rmdirs = []
            for d in dirs:
                path = os.path.join(root, d)
                key = self._local2remote(path).lower()
                if (key not in self._tree or
                    self._remote2local(self._tree[key]['path']) != path):
                    rmdirs.append(d)
                    self._logger.info('RM -RF %s' % (path))
                    self._rmrf(path)
                    changed = True

            for d in rmdirs:
                dirs.remove(d)

            for f in files:
                path = os.path.join(root, f)
                key = self._local2remote(path).lower()
                if (key not in self._tree or
                    self._remote2local(self._tree[key]['path']) != path):
                    self._logger.info('RM %s' % (path))
                    self._rm(path)
                    changed = True

        return changed

    def _rmrf(self, folder):
        for path in (os.path.join(folder, f) for f in os.listdir(folder)):
            if os.path.isdir(path):
                self._rmrf(path)
            else:
                os.unlink(path)
        os.rmdir(folder)

    def _rm(self, path):
        os.unlink(path)

    def _remove(self, path):
        if not os.path.exists(path):
            return
        if os.path.isdir(path):
            self._rmrf(path)
        else:
            self._rm(path)

    def _mkdir(self, d):
        self._logger.info('MKDIR %s' % (d))
        if not os.path.exists(d):
            os.mkdir(d)
        elif os.path.isfile(d):
            os.unlink(d)
            os.mkdir(d)

    def _get_file(self, from_path, to_path, modified=None):
        self._logger.info('FETCH %s -> %s' % (from_path, to_path))
        try:
            f, metadata = self.client.get_file_and_metadata(from_path)
        except Exception as e:
            self._logger.error('error fetching file')
            self._logger.exception(e)
            return  # will check later if we've got everything

        to_file = open(os.path.expanduser(to_path), 'wb')
        to_file.write(f.read())
        to_file.close()
        if modified:
            os.utime(to_path, (modified, modified))


class DBSession(session.DropboxSession):
    def link(self):
        request_token = self.obtain_request_token()

        url = self.build_authorize_url(request_token)
        print 'URL:', url
        print 'Please authorize this URL in the browser and then press enter'
        raw_input()

        self.obtain_access_token(request_token)
        self.set_token(self.token.key, self.token.secret)
        return [self.token.key, self.token.secret]

    def unlink(self):
        session.DropboxSession.unlink(self)


class FakeSecHead(object):
    def __init__(self, fp):
        self.fp = fp
        self.sechead = '[asection]\n'

    def readline(self):
        if self.sechead:
            try:
                return self.sechead
            finally:
                self.sechead = None
        else:
            return self.fp.readline()


def parse_config(cfg, opts):
    parser = SafeConfigParser()
    try:
        fp = open(os.path.expanduser(cfg), 'r')
    except:
        print 'Warning: can\'t open %s, using default values' % cfg
        return
    parser.readfp(FakeSecHead(fp))
    fp.close()

    for section_name in parser.sections():
        for name, value in parser.items(section_name):
            if name not in opts:
                raise Exception('Invalid config file option \'%s\'' % name)
            opts[name] = value


def create_logger(log, verbose):
    FORMAT = '%(asctime)-15s %(message)s'
    #logging.basicConfig(format=FORMAT)
    logger = logging.getLogger(LOGGER)
    if verbose:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)
    fh = logging.FileHandler(log)
    fh.setLevel(logging.DEBUG)
    formatter = logging.Formatter(FORMAT)
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    return logger


def main():
    options = {'log': '/tmp/dbdownload.log', 'config': '/etc/dbdownload.conf',
               'cache': '~/.dbdownload.cache', 'interval': 300, 'source': None,
               'target': None, 'verbose': False, 'reset': False, 'exec': None,
               'num': -1, 'poll': False}

    # first parse any command line arguments
    parser = OptionParser(description='Do one-way Dropbox synchronization')
    parser.add_option('--interval', '-i', type=int, help='check interval')
    parser.add_option('--num', '-n', type=int,
                      help='number of checks to perform')
    parser.add_option('--poll', '-p', action='store_true',
                      help='use the polling low-latency API')
    parser.add_option('--config', '-c', help='configuration file')
    parser.add_option('--cache', '-a', help='cache file')
    parser.add_option('--log', '-l', help='logfile')
    parser.add_option('--source', '-s',
                      help='source Dropbox directory to synchronize')
    parser.add_option('--target', '-t', help='local directory to download to')
    parser.add_option('--verbose', '-v', action='store_true',
                      help='enable verbose logging')
    parser.add_option('--reset', '-r', action='store_true',
                      help='reset synchronization')
    parser.add_option('--exec', '-x',
                      help='execute program when directory has changed')
    (opts, args) = parser.parse_args()
    if args:
        print 'Leftover command line arguments', args
        sys.exit(1)

    # parse configuration file
    parse_config((opts.config and [opts.config] or
                  [options['config']])[0], options)

    # override parameters from config file with cmdline options
    for a in options:
        v = getattr(opts, a)
        if v:
            options[a] = v

    if not options['source'] or not options['target']:
        raise Exception('Please provide source and target directories')

    locale.setlocale(locale.LC_ALL, 'C')  # to parse time correctly

    logger = create_logger(options['log'], options['verbose'])
    logger.info('*** DBdownload %s starting up ***' % (VERSION))

    dl = DBDownload(options['source'], options['target'], options['cache'],
                    options)
    if options['reset']:
        dl.reset()
    dl.start()

if __name__ == '__main__':
    main()
